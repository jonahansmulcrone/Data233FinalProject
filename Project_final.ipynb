{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "class sentenceQuality():\n",
    "    def __init__(self):\n",
    "        # do some initialization, optional\n",
    "        pass\n",
    "\n",
    "    def count_letters_and_numbers(input_string):\n",
    "        count = 0\n",
    "        for char in input_string:\n",
    "            if char.isalnum():\n",
    "                count += 1\n",
    "        return count\n",
    "\n",
    "    def calculateScores(self, tweet):\n",
    "        # please implement this function\n",
    "        # input: any tweet text\n",
    "        # output: a list of scores for the tweet, it must include: score for length, score for Polarity, score for Subjectivity, and at least one score of the following:\n",
    "        # https://en.wikipedia.org/wiki/Automated_readability_index\n",
    "        # https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests\n",
    "        # https://en.wikipedia.org/wiki/Gunning_fog_index\n",
    "        # https://en.wikipedia.org/wiki/SMOG\n",
    "        # https://en.wikipedia.org/wiki/Fry_readability_formula\n",
    "        # https://en.wikipedia.org/wiki/Coleman%E2%80%93Liau_index\n",
    "        # You should implement at least one score\n",
    "\n",
    "        texts = TextBlob(tweet)\n",
    "\n",
    "        subj = texts.sentiment.subjectivity\n",
    "        polar = texts.sentiment.polarity\n",
    "\n",
    "        charater = float(sentenceQuality.count_letters_and_numbers(tweet))\n",
    "        words = float(len(texts.words))\n",
    "        num_sentens = len(texts.sentences)\n",
    "        automated = float(4.71*(charater/words) + 0.5*(words/num_sentens) - 21.73)\n",
    "\n",
    "\n",
    "        if automated > 1:\n",
    "            automated = 1\n",
    "\n",
    "        x = len(tweet)/100\n",
    "        if x > 1.0:\n",
    "            x = 1.0;\n",
    "\n",
    "        obj = TwitterPositive()\n",
    "        y = obj.evaluateTweet(tweet)\n",
    "\n",
    "        if y < 0.5:\n",
    "            y = 0\n",
    "\n",
    "        return [x, polar, subj, automated]\n",
    "        pass\n",
    "\n",
    "    def calculateQuality(self, scores):\n",
    "        # please implement this function to calculate a final quality score between 0 and 1\n",
    "        # Input: a list of scores, which is the output of calculateScores\n",
    "        # output: 0 means low quality, 1 mean high quality\n",
    "\n",
    "        if scores[1] == 0.0 or scores[2] == 0.0:\n",
    "            return 0\n",
    "\n",
    "\n",
    "        ans = (sum(scores)/len(scores))\n",
    "\n",
    "        return ans\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def countWor(lis):\n",
    "    word_counts = {}\n",
    "    sum = 0\n",
    "    # Iterate over each string in the list\n",
    "    for string in lis:\n",
    "        # Split the string into words\n",
    "        words = string.split()\n",
    "        # Iterate over each word in the list\n",
    "        for word in words:\n",
    "            # Update the count for the word in the dictionary\n",
    "            word_counts[word] = word_counts.get(word, 0) + 1\n",
    "\n",
    "    # Print the word counts\n",
    "    for word, count in word_counts.items():\n",
    "        if count > 2:\n",
    "            sum = sum + count\n",
    "    return sum\n",
    "\n",
    "\n",
    "class TwitterPositive():\n",
    "    def __init__(self):\n",
    "        # do some initialization, optional\n",
    "        pass\n",
    "\n",
    "    def evaluateTweet(self, tweet):\n",
    "        # please implement this function\n",
    "        # input: any tweet text\n",
    "        # output: a score [0,1], 0 means it is low quality and negative, 1 means it is high quality and positive\n",
    "\n",
    "        positive_words = [\n",
    "            'good', 'excellent', 'great', 'awesome', 'fantastic',\n",
    "            'amazing', 'wonderful', 'superb', 'brilliant', 'outstanding',\n",
    "            'terrific', 'fabulous', 'incredible', 'perfect', 'marvelous',\n",
    "            'delightful', 'splendid', 'phenomenal', 'exceptional', 'stellar',\n",
    "            'remarkable', 'extraordinary', 'top-notch', 'first-rate', 'superior',\n",
    "            'impressive', 'magnificent', 'glorious', 'sublime', 'majestic',\n",
    "            'divine', 'exemplary', 'praiseworthy', 'admirable', 'commendable',\n",
    "            'heartwarming', 'joyful', 'uplifting', 'inspiring', 'positive',\n",
    "            'optimistic', 'ecstatic', 'blissful', 'euphoric', 'thrilling',\n",
    "            'sensational', 'electrifying', 'captivating', 'enchanting', 'charming',\n",
    "            'enticing', 'alluring', 'engaging', 'invigorating', 'refreshing',\n",
    "            'energizing', 'stimulating', 'vibrant', 'dynamic', 'alive', 'radiant',\n",
    "            'cheerful', 'lively', 'vivacious', 'buoyant', 'spirited', 'exhilarating',\n",
    "            'festive', 'celebratory', 'jubilant', 'festive', 'gleeful', 'playful',\n",
    "            'delicious', 'scrumptious', 'mouthwatering', 'tasty', 'flavorful',\n",
    "            'satisfying', 'fulfilling', 'gratifying', 'nourishing', 'wholesome',\n",
    "            'beneficial', 'heavenly', 'divine', 'sumptuous', 'lavish', 'opulent',\n",
    "            'luxurious', 'gorgeous', 'beautiful', 'stunning', 'breathtaking',\n",
    "            'mesmerizing', 'enchanting', 'fascinating', 'captivating', 'hypnotic',\n",
    "            'bewitching', 'enticing', 'spellbinding', 'charismatic', 'alluring', 'wonderful'\n",
    "        ]\n",
    "\n",
    "        negative_words = [\n",
    "            'bad', 'poor', 'terrible', 'horrible', 'awful',\n",
    "            'mediocre', 'subpar', 'inferior', 'unsatisfactory', 'disappointing',\n",
    "            'unpleasant', 'unfavorable', 'negative', 'dreadful', 'lousy',\n",
    "            'abysmal', 'atrocious', 'ghastly', 'miserable', 'wretched',\n",
    "            'deplorable', 'appalling', 'disgusting', 'repulsive', 'revolting',\n",
    "            'offensive', 'vile', 'disgraceful', 'shameful', 'abominable',\n",
    "            'detestable', 'horrifying', 'repugnant', 'odious', 'noxious',\n",
    "            'repellent', 'unsavory', 'distasteful', 'unwelcome', 'unwanted',\n",
    "            'disheartening', 'discouraging', 'demoralizing', 'depressing', 'gloomy',\n",
    "            'melancholy', 'dreary', 'sorrowful', 'mournful', 'bleak',\n",
    "            'despondent', 'dismal', 'grievous', 'tragic', 'pitiful',\n",
    "            'heartbreaking', 'heart-wrenching', 'saddening', 'tearful', 'unfortunate',\n",
    "            'unlucky', 'troublesome', 'problematic', 'difficult', 'challenging',\n",
    "            'frustrating', 'annoying', 'irritating', 'exasperating', 'aggravating',\n",
    "            'bothersome', 'disruptive', 'displeasing', 'discontented', 'disgruntled',\n",
    "            'grumpy', 'miserable', 'crummy', 'irksome', 'pesty', 'vexing',\n",
    "            'maddening', 'provoking', 'enraging', 'infuriating', 'outrageous',\n",
    "            'intolerable', 'unbearable', 'exasperating', 'anger-inducing', 'irksome',\n",
    "            'troublesome', 'annoying', 'bothersome', 'irritating', 'frustrating',\n",
    "            'aggravating', 'infuriating', 'vexing', 'maddening', 'galling',\n",
    "            'exasperating', 'peeving', 'perturbing', 'trying', 'nagging'\n",
    "        ]\n",
    "\n",
    "        delimiters = \"[,;|\\\\s]+\"\n",
    "\n",
    "        words = re.split(delimiters, tweet)\n",
    "\n",
    "        two_gram = TwitterPositive.twoGram(words)\n",
    "\n",
    "        num_positive_words = sum(4 for word in tweet.split() if word.lower() in positive_words)\n",
    "        num_negative_words = sum(1 for word in tweet.split() if word.lower() in negative_words)\n",
    "        # print(num_positive_words)\n",
    "        # print(num_negative_words)\n",
    "\n",
    "        total_words = len(tweet.split())\n",
    "        # print(total_words)\n",
    "        if total_words == 0:\n",
    "            return 0.0\n",
    "        else:\n",
    "            positive_ratio = num_positive_words / total_words\n",
    "\n",
    "        occu = countWor(two_gram)\n",
    "\n",
    "        # print(occu)\n",
    "\n",
    "        score = positive_ratio - ((occu + num_negative_words) / total_words)\n",
    "\n",
    "        score = max(0, min(score, 1))\n",
    "\n",
    "        # print(two_gram)\n",
    "\n",
    "        return score\n",
    "\n",
    "    def twoGram(lis):\n",
    "\n",
    "        result = []\n",
    "\n",
    "        for i in range(len(lis)):\n",
    "            if i == len(lis) - 1:\n",
    "                break\n",
    "            else:\n",
    "                result.append(lis[i] + \" \" + lis[i + 1])\n",
    "\n",
    "        return result\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T17:57:23.797135700Z",
     "start_time": "2024-05-14T17:57:20.485773500Z"
    }
   },
   "id": "4af6fee449ef2055",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "business_url = \"https://api.yelp.com/v3/businesses/search?location=Seattle&limit=20\"\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer wxUp4LTf7UM8ofjG2H1lZ7kSmi3n_PkASO6-8ON1lpsmT9yqKjbmFXApXcfXpjn_K5Zj_rpYKjGWGihGz70xkIRWerJoaIeGqrxLnE6tbpKZpQfl_fb0KtVVs2wwZnYx\"\n",
    "}\n",
    "\n",
    "#gloss over, not using yelp fusion api:\n",
    "response = {\n",
    "    \"status_code\": 400\n",
    "}\n",
    "\n",
    "if response.get(\"status_code\", 200) == 200: \n",
    "\n",
    "    data = response.json()\n",
    "    businesses = data.get('businesses')\n",
    "\n",
    "    reviews = []\n",
    "\n",
    "    for business in businesses:\n",
    "\n",
    "        business_id = business['id']\n",
    "\n",
    "        review_url = f\"https://api.yelp.com/v3/businesses/\" + business_id + \"/reviews?limit=1&sort_by=yelp_sort\"\n",
    "        response = requests.get(review_url, headers=headers)\n",
    "\n",
    "        print(response.json())\n",
    "\n",
    "        current_review = {\n",
    "            \"business_name\": business['name'],\n",
    "            \"city\": business['location']['city'],\n",
    "            \"category\": business['categories'][0]['title']\n",
    "        }\n",
    "\n",
    "        reviews.append(current_review)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "input_file_path = \"yelp_dataset/yelp_academic_dataset_review.json\"\n",
    "output_file_path = \"reduced_reviews.json\"\n",
    "\n",
    "\n",
    "with open(input_file_path, \"r\") as input_file:\n",
    "\n",
    "    with open(output_file_path, \"w\") as output_file:\n",
    "\n",
    "        for i in range(550):\n",
    "            line = input_file.readline().strip()\n",
    "            if line: \n",
    "                output_file.write(line + '\\n')\n",
    "\n",
    "with open(output_file_path, \"r\") as output_file:\n",
    "    first_100_reviews = [json.loads(line) for line in output_file]\n",
    "\n",
    "with open(output_file_path, \"w\") as output_file:\n",
    "    json.dump(first_100_reviews, output_file, indent=2)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "business_data = {}\n",
    "with open(\"yelp_dataset/yelp_academic_dataset_business.json\", \"r\", encoding=\"utf-8\") as business_file:\n",
    "    for line in business_file:\n",
    "        business = json.loads(line)\n",
    "        business_data[business[\"business_id\"]] = business\n",
    "\n",
    "first_business_id = next(iter(business_data.keys()))\n",
    "print(first_business_id)\n",
    "\n",
    "first_business = next(iter(business_data.values()))\n",
    "print(first_business)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "with open(\"yelp_dataset/reduced_reviews.json\", \"r\", encoding=\"utf-8\") as reviews_file:\n",
    "    reduced_reviews = json.load(reviews_file)\n",
    "\n",
    "\n",
    "reviews_with_state_and_category = []\n",
    "for review in reduced_reviews:\n",
    "    business_id = review.get(\"business_id\")\n",
    "    if business_id:\n",
    "        \n",
    "        business = business_data.get(business_id)\n",
    "        if business:\n",
    "            \n",
    "            review[\"state\"] = business.get(\"state\")\n",
    "            review[\"category\"] = business.get(\"categories\", \"\").split(\", \")[0]\n",
    "            review[\"city\"] = business.get(\"city\")\n",
    "        else:\n",
    "            print(f\"No business found for ID: {business_id}\")\n",
    "    reviews_with_state_and_category.append(review)\n",
    "\n",
    "\n",
    "with open(\"reviews_join_business\", \"w\", encoding=\"utf-8\") as output_file:\n",
    "    json.dump(reviews_with_state_and_category, output_file, indent=2)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#Encode Dates as Seasons\n",
    "\n",
    "def get_season(date_str):\n",
    "    # Parse the date string into a datetime object\n",
    "    date_obj = datetime.strptime(date_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # Determine the season based on the month\n",
    "    month = date_obj.month\n",
    "    if 3 <= month <= 5:\n",
    "        return \"Spring\"\n",
    "    elif 6 <= month <= 8:\n",
    "        return \"Summer\"\n",
    "    elif 9 <= month <= 11:\n",
    "        return \"Autumn\"\n",
    "    else:\n",
    "        return \"Winter\"\n",
    "\n",
    "# Read the JSON file\n",
    "with open(\"yelp_dataset/reviews_join_business.json\", \"r\", encoding=\"utf-8\") as input_file:\n",
    "    reviews_data = json.load(input_file)\n",
    "\n",
    "# Filter objects with seasons\n",
    "reviews_with_season = []\n",
    "for review in reviews_data:\n",
    "    if \"date\" in review:\n",
    "        qualt = sentenceQuality()\n",
    "        review[\"season\"] = get_season(review[\"date\"])\n",
    "        review[\"Quality\"] = qualt.calculateQuality(qualt.calculateScores(review[\"text\"]))\n",
    "        reviews_with_season.append(review)\n",
    "\n",
    "# Save objects with seasons into a new file\n",
    "with open(\"reviews_with_season.json\", \"w\", encoding=\"utf-8\") as output_file:\n",
    "    json.dump(reviews_with_season, output_file, indent=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T17:59:27.679674500Z",
     "start_time": "2024-05-14T17:59:25.344390Z"
    }
   },
   "id": "a6ddd7be21303590",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4\n",
      "Predicted Quality KNN: [2.]\n",
      "Accuracy: 0.3939393939393939\n",
      "Predicted Quality using decision tree: [2.]\n",
      "Mean Squared Error: 1.5355456314450229\n",
      "Linear regssion [2.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "class KNNModel:\n",
    "    def __init__(self):\n",
    "        self.knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        self.knn_model.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        return self.knn_model.predict(X_test)\n",
    "\n",
    "with open(\"reviews_with_season.json\", \"r\", encoding=\"utf-8\") as input_file:\n",
    "    reviews_data = json.load(input_file)\n",
    "\n",
    "\n",
    "stars = [data['stars'] for data in reviews_data]\n",
    "labels = [data[\"Quality\"] for data in reviews_data]\n",
    "seas = [data[\"season\"] for data in reviews_data]\n",
    "sentences = [data['text'] for data in reviews_data]\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_categories = label_encoder.fit_transform(seas)\n",
    "combined_labels = np.column_stack((labels, encoded_categories))\n",
    "\n",
    "# Reshape the combined labels to a 2D array\n",
    "labels_resh = np.array(combined_labels).reshape(-1, 2)\n",
    "#labels_resh = np.array(labels).reshape(-1, 1)\n",
    "\n",
    "#print(encoded_categories)\n",
    "#print(seas)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(labels_resh, stars, test_size=0.1, random_state=100)\n",
    "\n",
    "# Initialize kNNsentenceQuality object\n",
    "obj = KNNModel()\n",
    "obj.train(X_train, y_train)\n",
    "\n",
    "new_sentences = \"Love this store!  Who doesn't!  The salad bar is fresh and they have all types of ethnic food to try.  N-JOY\"\n",
    "qualt = sentenceQuality()\n",
    "predictions = obj.predict(X_test)\n",
    "\n",
    "# Calculate accuracy by comparing predictions with actual labels\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "answer = qualt.calculateQuality(qualt.calculateScores(new_sentences))\n",
    "prd = np.array([answer, 3]).reshape(1, 2)\n",
    "quality = obj.predict(prd)\n",
    "print(\"Predicted Quality KNN:\", quality)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(labels_resh, stars, test_size=0.3, random_state=100)\n",
    "vectorizer = CountVectorizer()\n",
    "#X_train_transformed = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "decision_tree_model = DecisionTreeClassifier()\n",
    "\n",
    "# Train the decision tree model\n",
    "decision_tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "#X_test_transformed = vectorizer.transform(X_test)\n",
    "accuracy = decision_tree_model.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "prediction = decision_tree_model.predict(prd)\n",
    "print(\"Predicted Quality using decision tree:\", prediction)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_labels, stars, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the linear regression model\n",
    "linear_reg_model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "linear_reg_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = linear_reg_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Linear regssion\", np.round(linear_reg_model.predict(prd)))\n",
    "\n",
    "\n",
    "class mod:\n",
    "    def __init__(self):\n",
    "        self.reviews_data = reviews_data\n",
    "    def getSEn(self):\n",
    "        return reviews_data\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T18:00:20.844241100Z",
     "start_time": "2024-05-14T18:00:20.815135500Z"
    }
   },
   "id": "dfb72aaede2902e7",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from models import mod\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "n = mod()\n",
    "\n",
    "reviews_data = n.getSEn()\n",
    "stars = [data['stars'] for data in reviews_data]\n",
    "labels = [data[\"Quality\"] for data in reviews_data]\n",
    "seas = [data[\"season\"] for data in reviews_data]\n",
    "#print(labels)\n",
    "\n",
    "\n",
    "\n",
    "# Sentiment Analysis Results\n",
    "# Assuming you have sentiment_scores for each review\n",
    "\n",
    "# Histogram of sentiment scores\n",
    "plt.hist(labels, bins=20, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Sentiment Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Sentiment Scores')\n",
    "plt.show()\n",
    "\n",
    "# Rating Distributions of Yelp Reviews\n",
    "# Assuming you have star ratings for each review\n",
    "\n",
    "# Histogram of star ratings\n",
    "sns.histplot(stars, bins=5, kde=False, color='orange')\n",
    "plt.xlabel('Star Rating')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Star Ratings')\n",
    "plt.show()\n",
    "\n",
    "# Relationship Between Weather Conditions and Restaurant Recommendations\n",
    "# Assuming you have weather data and number of restaurant recommendations\n",
    "\n",
    "# Scatter plot of temperature vs. recommendations\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the \"seas\" variable\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_seas = label_encoder.fit_transform(seas)\n",
    "\n",
    "correlation = np.corrcoef(labels, stars)[0, 1]\n",
    "\n",
    "# Plot a scatter plot with correlation coefficient\n",
    "sns.regplot(x=stars, y=labels, scatter_kws={'alpha':0.5})\n",
    "plt.ylabel('Sentence Quality')\n",
    "plt.xlabel('Star Rating')\n",
    "plt.title('Relationship Between Season and Star Ratings (Correlation: {:.2f})'.format(correlation))\n",
    "plt.show()\n",
    "\n",
    "sns.regplot(x=encoded_seas, y=labels, scatter_kws={'alpha':0.5})\n",
    "plt.xlabel('Seasons')\n",
    "plt.ylabel('Sentence Quality')\n",
    "plt.title('Relationship Between Season and Star Ratings')\n",
    "plt.xticks(ticks=range(len(label_encoder.classes_)), labels=label_encoder.classes_, rotation=45)\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2bdb2d5ca8254d4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
